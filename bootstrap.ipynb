{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wtfk7SOX5eZY",
        "outputId": "b140de52-a0e5-4ffd-96c5-fd649ec7f1c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-766c6e17902c>:8: DtypeWarning: Columns (16,18,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  complaints_allegation = pd.read_csv(file_path + 'complaints-allegation.csv')\n",
            "<ipython-input-11-766c6e17902c>:9: DtypeWarning: Columns (4,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  officers = pd.read_csv(file_path + 'final-profiles.csv')\n",
            "<ipython-input-11-766c6e17902c>:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sustained_df.loc[:, 'violence_classification'] = sustained_df['allegation_category'].map(category_mapping).fillna('Non-Violent')\n",
            "<ipython-input-11-766c6e17902c>:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  sustained_df.loc[:, 'combined_rank'] = sustained_df['cleaned_rank_x'].replace(low_frequency_ranks, 'Higher Ranks')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrap Confidence Intervals:\n",
            "combined_rank  DETECTIVE  FIELD TRAINING OFFICER  Higher Ranks  \\\n",
            "0.025           0.339177                0.288981      0.214309   \n",
            "0.975           0.355240                0.322605      0.246924   \n",
            "\n",
            "combined_rank  POLICE OFFICER  SERGEANT  \n",
            "0.025                0.240160  0.256493  \n",
            "0.975                0.244084  0.267745  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "file_path = '/content/drive/MyDrive/hw/causal/chicago-police/' # change this\n",
        "\n",
        "# Load the datasets\n",
        "complaints_allegation = pd.read_csv(file_path + 'complaints-allegation.csv')\n",
        "officers = pd.read_csv(file_path + 'final-profiles.csv')\n",
        "salary = pd.read_csv(file_path + 'salary_2002-2017_2017-09.csv')\n",
        "salary_ranks = pd.read_csv(file_path + 'salary-ranks_2002-2017_2017-09.csv')\n",
        "merged_data_1 = pd.merge(salary_ranks, complaints_allegation, left_on='link_UID', right_on='link_UID', how='left')\n",
        "merged_data = pd.merge(merged_data_1, officers, left_on='link_UID', right_on='link_UID', how='left')\n",
        "# selected_columns = merged_data[['link_UID', 'race','gender','birth_year','salary', 'appointed_date', 'cleaned_rank_x','allegation_category','final_finding','penalty_code','number_of_days']]\n",
        "# selected_columns.sample(n=10)\n",
        "sustained_df = merged_data[merged_data['final_finding'] == 'SUSTAINED']\n",
        "outcome_counts = sustained_df['allegation_category'].value_counts(dropna=False)\n",
        "# outcome_counts.head(10)\n",
        "category_mapping = {\n",
        "    'MISCELLANEOUS': 'Non-Violent',\n",
        "    'DOMESTIC ALTERCATION - PHYSICAL ABUSE': 'Violent',\n",
        "    'NEGLECT OF DUTY': 'Non-Violent',\n",
        "    'EXCESSIVE FORCE - USE OF FIREARM / OFF DUTY - INJURY': 'Violent',\n",
        "    'UNNECESSARY DISPLAY OF WEAPON / ON DUTY': 'Non-Violent',\n",
        "    'USE OF PROFANITY': 'Non-Violent',\n",
        "    'EXCESSIVE FORCE / OFF DUTY - NO INJURY': 'Violent',\n",
        "    'EXCESSIVE FORCE / On DUTY - INJURY': 'Violent',\n",
        "    'CONDUCT UNBECOMING': 'Non-Violent',\n",
        "    'NO INJURY': \"Non-Violent\",\n",
        "    'PUSH/PULL/GRAB': \"Violent\",\n",
        "    'INJURY': \"Violent\",\n",
        "    'FALSE': \"Non-Violent\",\n",
        "    'FAIL TO SUBMIT': \"Non-Violent\",\n",
        "    'INADEQUATE / FAILURE TO PROVIDE SERVICE': \"Non-Violent\",\n",
        "    'HARASSMENT': \"Non-Violent\",\n",
        "    'EXCESSIVE FORCE - USE OF FIREARM / OFF DUTY - NO INJURY': \"Violent\",\n",
        "    'VERBAL ABUSE': \"Non-Violent\",\n",
        "    'FAIL TO OBTAIN A COMPLAINT REGISTER NUMBER': \"Non-Violent\",\n",
        "    'LEAVING ASSIGNMENT (DISTRICT, BEAT, SECTOR, COURT)': \"Non-Violent\",\n",
        "    'INTOXICATED OFF DUTY': \"Non-Violent\",\n",
        "    'CLOSED HAND STRIKE (PUNCH)': \"Violent\",\n",
        "}\n",
        "# sustained_df['violence_classification'] = sustained_df['allegation_category'].map(category_mapping).fillna('Non-Violent')\n",
        "sustained_df.loc[:, 'violence_classification'] = sustained_df['allegation_category'].map(category_mapping).fillna('Non-Violent')\n",
        "\n",
        "\n",
        "# Combine low-frequency ranks into a single category\n",
        "low_frequency_ranks = ['CAPTAIN', 'CIVILIAN', 'COMMANDER', 'DEPUTY CHIEF', 'LIEUTENANT', 'INVESTIGATOR']\n",
        "# sustained_df['combined_rank'] = sustained_df['cleaned_rank_x'].replace(low_frequency_ranks, 'Higher Ranks')\n",
        "sustained_df.loc[:, 'combined_rank'] = sustained_df['cleaned_rank_x'].replace(low_frequency_ranks, 'Higher Ranks')\n",
        "\n",
        "\n",
        "\n",
        "# Number of bootstrap samples\n",
        "n_bootstrap_samples = 1000\n",
        "\n",
        "# Convert the dataframe to a numpy array for faster operations\n",
        "# sustained_array = sustained_df[['combined_rank', 'violence_classification']].to_numpy()\n",
        "\n",
        "# # Unique ranks and their indices\n",
        "# unique_ranks, rank_indices = np.unique(sustained_array[:, 0], return_inverse=True)\n",
        "\n",
        "# Function to calculate the proportion of violent allegations by combined rank\n",
        "# def calculate_proportion(array, rank_indices):\n",
        "#     proportions = []\n",
        "#     for rank in np.unique(rank_indices):\n",
        "#         mask = rank_indices == rank\n",
        "#         proportion = np.mean(array[mask, 1] == 'Violent')\n",
        "#         proportions.append(proportion)\n",
        "#     return np.array(proportions)\n",
        "\n",
        "# # Initialize list to store bootstrap results\n",
        "# bootstrap_results = []\n",
        "\n",
        "# # Bootstrap sampling\n",
        "# for _ in range(n_bootstrap_samples):\n",
        "#     bootstrap_sample_indices = np.random.choice(np.arange(sustained_array.shape[0]), size=sustained_array.shape[0], replace=True)\n",
        "#     bootstrap_sample = sustained_array[bootstrap_sample_indices]\n",
        "#     bootstrap_results.append(calculate_proportion(bootstrap_sample, rank_indices[bootstrap_sample_indices]))\n",
        "\n",
        "# # Convert results to DataFrame\n",
        "# bootstrap_df = pd.DataFrame(bootstrap_results, columns=unique_ranks)\n",
        "\n",
        "# # Calculate confidence intervals (e.g., 95% CI)\n",
        "# confidence_intervals = bootstrap_df.quantile([0.025, 0.975])\n",
        "\n",
        "# # Display the results\n",
        "# print(\"Bootstrap Confidence Intervals:\")\n",
        "# print(confidence_intervals)\n",
        "\n",
        "\n",
        "################################\n",
        "def calculate_proportion(df):\n",
        "    return df.groupby('combined_rank')['violence_classification'].apply(lambda x: (x == 'Violent').mean())\n",
        "\n",
        "# Initialize list to store bootstrap results\n",
        "bootstrap_results = []\n",
        "\n",
        "# Bootstrap sampling\n",
        "for _ in range(n_bootstrap_samples):\n",
        "    bootstrap_sample = sustained_df.sample(frac=1, replace=True)\n",
        "    bootstrap_results.append(calculate_proportion(bootstrap_sample))\n",
        "\n",
        "# Convert results to DataFrame\n",
        "bootstrap_df = pd.DataFrame(bootstrap_results)\n",
        "\n",
        "# Calculate confidence intervals (e.g., 95% CI)\n",
        "confidence_intervals = bootstrap_df.quantile([0.025, 0.975])\n",
        "\n",
        "# Display the results\n",
        "print(\"Bootstrap Confidence Intervals:\")\n",
        "print(confidence_intervals)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DnjyByX6Bh1",
        "outputId": "9e2c69dd-0a36-4d2c-a1af-4c28608b812f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "combined_rank\n",
            "POLICE OFFICER            206837\n",
            "SERGEANT                   22464\n",
            "DETECTIVE                  13559\n",
            "FIELD TRAINING OFFICER      3071\n",
            "Higher Ranks                2655\n",
            "Name: count, dtype: int64\n",
            "combined_rank           violence_classification\n",
            "DETECTIVE               Non-Violent                  8853\n",
            "                        Violent                      4706\n",
            "FIELD TRAINING OFFICER  Non-Violent                  2133\n",
            "                        Violent                       938\n",
            "Higher Ranks            Non-Violent                  2042\n",
            "                        Violent                       613\n",
            "POLICE OFFICER          Non-Violent                156756\n",
            "                        Violent                     50081\n",
            "SERGEANT                Non-Violent                 16576\n",
            "                        Violent                      5888\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(sustained_df['combined_rank'].value_counts())\n",
        "print(sustained_df.groupby('combined_rank')['violence_classification'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M7YYYjIreY8"
      },
      "source": [
        "#the rest is copied from synthetic data notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9HP79zHQzmg"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import random\n",
        "\n",
        "\n",
        "def get_smf_model_a_param(ols, df):\n",
        "    \"\"\"\n",
        "    Fit a model with statsmodels\n",
        "    Return the parameter corresponding to the treatment\n",
        "    \"\"\"\n",
        "    return smf.ols(ols, data=df).fit().params['a']\n",
        "\n",
        "\n",
        "def get_sklearn_model_a_param(ols, df):\n",
        "    \"\"\"\n",
        "    Fit a model with sklearn\n",
        "    Return the parameter corresponding to the treatment\n",
        "    \"\"\"\n",
        "    target = ols.split(\"~\")[0].strip()\n",
        "    inputs = ols.split(\"~\")[1].strip().split(\" + \")\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(df[inputs], df[target])\n",
        "\n",
        "    return model.coef_[inputs.index(\"a\")]\n",
        "\n",
        "def observed(n=100, c_dim=6, ols=\"y ~ a\"):\n",
        "      # confounders = race (c1) and gender (c2)\n",
        "    c1 = np.random.binomial(n=1, p=0.423, size=n)\n",
        "\n",
        "    # choose p based on distribution of male vs female officers in the data\n",
        "    c2 = np.random.binomial(n=1, p=0.8763, size=n)\n",
        "\n",
        "    # a = rank/treatment\n",
        "    a = np.random.randint(1, 7+c1+c2, n)\n",
        "    # a = np.random.randint(n=1 + c_dim - c, p=0.5, size=n)\n",
        "    # a = (a > 0).astype(np.int32)\n",
        "    y = np.random.binomial(n=a + c1+c2, p=0.5)\n",
        "\n",
        "    df = pd.DataFrame(data=dict(c1=c1, c2=c2, a=a, y=y))\n",
        "    a_param = get_smf_model_a_param(ols, df)\n",
        "    # a_param = get_sklearn_model_a_param(ols, df)\n",
        "\n",
        "    print(a_param)\n",
        "\n",
        "    return a_param\n",
        "\n",
        "\n",
        "# def observed(n=100, c_dim=6, ols=\"y ~ a\"):\n",
        "#     \"\"\"\n",
        "#     The observed data distribution\n",
        "#       C: roll a k-sided die and record the result\n",
        "#       A: flip `1 + k - C` fair coins, and record 1 if at least one flip lands heads\n",
        "#       Y: flip `C + A` fair coins, and record the number of heads\n",
        "#     \"\"\"\n",
        "#     # confounders = race (c1) and gender (c2)\n",
        "#     c1 = np.random.randint(1, 6, n)\n",
        "\n",
        "#     # choose p based on distribution of male vs female officers in the data\n",
        "#     c2 = np.random.binomial(n=1, p=0.8763, size=n)\n",
        "\n",
        "#     # a = rank/treatment\n",
        "#     a = np.random.binomial(n=1+c1+c2, p=0.5, size=n) * (c1 + c2)\n",
        "#     # a = np.random.randint(n=1 + c_dim - c, p=0.5, size=n)\n",
        "#     # a = (a > 0).astype(np.int32)\n",
        "#     y = np.random.binomial(n=a + c, p=0.5)\n",
        "\n",
        "#     df = pd.DataFrame(data=dict(c=c, a=a, y=y))\n",
        "#     a_param = get_smf_model_a_param(ols, df)\n",
        "#     # a_param = get_sklearn_model_a_param(ols, df)\n",
        "\n",
        "#     return a_param\n",
        "\n",
        "# def observed(n=100, ols=\"y ~ a\"):\n",
        "#     \"\"\"\n",
        "#     The observed data distribution\n",
        "#       C: roll a k-sided die and record the result\n",
        "#       A: flip `1 + k - C` fair coins, and record 1 if at least one flip lands heads\n",
        "#       Y: flip `C + A` fair coins, and record the number of heads\n",
        "#     \"\"\"\n",
        "#     # confounders = race (c1) and gender (c2)\n",
        "#     c1 = np.random.binomial(n=1, p=0.423, size=n) #white prob: 0.423\n",
        "\n",
        "#     # choose p based on distribution of male vs female officers in the data\n",
        "#     c2 = np.random.binomial(n=1, p=0.8763, size=n)\n",
        "\n",
        "\n",
        "#     # a = rank/treatment\n",
        "#     # a = np.random.binomial(n=1+c1+c2, p=0.5, size=n) * (c1 + c2)\n",
        "#     # a = random.random()* (c1 + c2)\n",
        "#     # a = np.random.binomial(n=(1 + c1 + c2), p=0.5, size=n)\n",
        "#     # p = 0.3 + 0.2 * c1 + 0.2 * c2 + 0.3 * (c1 & c2)  # Increased probability when both c1 and c2 are 1\n",
        "\n",
        "#     # a = np.random.binomial(n=1, p=p, size=n)\n",
        "#     min_a = 0\n",
        "#     max_a = 10\n",
        "#     max_a_modified = max_a + 5 * c1 + 5 * c2\n",
        "\n",
        "# # Generate A uniformly within the modified range\n",
        "#     a = np.random.uniform(min_a, max_a_modified)\n",
        "#     # a = 7 + c1 + c2 +\n",
        "\n",
        "\n",
        "#     # a = np.random.randint(n=1 + c_dim - c, p=0.5, size=n)\n",
        "#     # a = (a > 0).astype(np.int32)\n",
        "#     y = np.random.binomial(n=np.round(a).astype(int) + c1 + c2, p=0.5,size = n)\n",
        "#     # y = random.random() * (a + c1 + c2)\n",
        "\n",
        "#     df = pd.DataFrame(data=dict(c1=c1, c2=c2, a=a, y=y))\n",
        "#     a_param = get_smf_model_a_param(ols, df)\n",
        "#     # a_param = get_sklearn_model_a_param(ols, df)\n",
        "\n",
        "#     return a_param\n",
        "\n",
        "\n",
        "# def observed(n=100, c_dim=6, ols=\"y ~ a\"):\n",
        "#     \"\"\"\n",
        "#     The observed data distribution\n",
        "#       C: roll a k-sided die and record the result\n",
        "#       A: flip `1 + k - C` fair coins, and record 1 if at least one flip lands heads\n",
        "#       Y: flip `C + A` fair coins, and record the number of heads\n",
        "#     \"\"\"\n",
        "#     birth_year = np.random.randint(1950, 2000, n)\n",
        "#     gender = np.random.binomial(1, 0.5, n)  # 0 for female, 1 for male\n",
        "#     race = np.random.randint(0, 3, n)\n",
        "\n",
        "#     appointed_date = birth_year + np.random.randint(18, 31, n)  # Age at appointment between 18-30\n",
        "#     rank = gender + (2024 - appointed_date) // 10 + race  # Simplified ranking logic\n",
        "\n",
        "#     allegation_category = race  # Direct dependency from race\n",
        "\n",
        "#     # Further dependent variables based on rank\n",
        "#     final_finding = rank % 3  # Simplified example\n",
        "#     penalty_code = rank % 5  # Simplified example\n",
        "#     number_of_days_suspended = final_finding * 2 + penalty_code * 3  # Simplified calculation\n",
        "\n",
        "\n",
        "\n",
        "#     c = np.random.randint(1, 1 + c_dim, n)\n",
        "#     a_tmp = np.random.binomial(n=1 + c_dim - c, p=0.5, size=n)\n",
        "#     a = (a_tmp > 0).astype(np.int32)\n",
        "#     y = np.random.binomial(n=a + c, p=0.5)\n",
        "\n",
        "#     df = pd.DataFrame(data=dict(c=c, a=a, y=y))\n",
        "#     a_param = get_smf_model_a_param(ols, df)\n",
        "\n",
        "#     return a_param\n",
        "\n",
        "\n",
        "def randomized(n=100, c_dim = 6, ols=\"y ~ a\"):\n",
        "    \"\"\"\n",
        "    The same distribution, except A is replaced with a fair coin f\n",
        "      C: roll a k-sided die and record the result\n",
        "      A: flip a single fair coin, and record 1 if it lands heads\n",
        "      Y: flip `C + A` fair coins, and record the number of heads\n",
        "    \"\"\"\n",
        "\n",
        "    c = np.random.randint(1, 1 + c_dim, n)\n",
        "    a = np.random.binomial(n=1, p=0.5, size=n)\n",
        "    y = np.random.binomial(n=a + c, p=0.5)\n",
        "\n",
        "    df = pd.DataFrame(data=dict(c=c, a=a, y=y))\n",
        "    a_param = get_smf_model_a_param(ols, df)\n",
        "\n",
        "    return a_param\n",
        "def experiment(dist, n=100, ols=\"y ~ a\", repeats=1):\n",
        "    \"\"\"\n",
        "    Run an experiment with the given kwargs\n",
        "      dist: either \"observed\" or \"randomized\" distribution\n",
        "      n: the number of samples to draw from the distribution\n",
        "      c_dim: possible values that C can take (number of sides of the die)\n",
        "      ols: regression model; either \"y ~ a\" or \"y ~ a + c\"\n",
        "    \"\"\"\n",
        "    if dist == \"observed\":\n",
        "        func = observed\n",
        "    elif dist == \"randomized\":\n",
        "        func = randomized\n",
        "    else:\n",
        "        raise ValueError(dist)\n",
        "\n",
        "    np.random.seed(42)\n",
        "    results = [func(n=n, ols=ols) for i in range(repeats)]\n",
        "    err = \"\"\n",
        "    if repeats > 1:\n",
        "        err = f\" ± {np.std(results):.3f}\"\n",
        "    print(f\"{np.mean(results):.3f}{err}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JajIMrNH9isq",
        "outputId": "3a66f3be-fa49-49e2-bb38-777ea299bf3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4277590315958376\n",
            "0.47627478753541075\n",
            "0.462743032276602\n",
            "0.5462407862407856\n",
            "0.5774672915879966\n",
            "0.4976138828633404\n",
            "0.5884165946029848\n",
            "0.635354879451499\n",
            "0.6311625228473424\n",
            "0.5244522691705787\n",
            "0.537 ± 0.068\n"
          ]
        }
      ],
      "source": [
        "experiment(\"observed\", n=100, ols=\"y ~ a\", repeats=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVBrX3ZLBOoe",
        "outputId": "c32510e0-3f73-45eb-a5c4-14c07fe3646d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.586 ± 0.338\n"
          ]
        }
      ],
      "source": [
        "experiment(\"randomized\", n=100, ols=\"y ~ a\", repeats=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26IEh0SjBVBt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}