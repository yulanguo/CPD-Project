{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX5rhRH534IB"
      },
      "source": [
        "### Synthetic data example\n",
        "\n",
        "Here we're building a simple model with two confounders (race and gender) and a binary treatment of high vs low rank. We're generating a weight for each rank, and the difference between the two is our expected causal effect, and we generate our final outcome based off of the confounders and treatment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "StbmXb762aSb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DelMlLoCmnSe"
      },
      "outputs": [],
      "source": [
        "def get_smf_model_a_param(ols, df):\n",
        "    \"\"\"\n",
        "    Fit a model with statsmodels\n",
        "    Return the parameter corresponding to the treatment\n",
        "    \"\"\"\n",
        "    return smf.ols(ols, data=df).fit().params['a']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7Kw5Qz66mogF"
      },
      "outputs": [],
      "source": [
        "def get_sklearn_model_a_param(ols, df):\n",
        "    \"\"\"\n",
        "    Fit a model with sklearn\n",
        "    Return the parameter corresponding to the treatment\n",
        "    \"\"\"\n",
        "    target = ols.split(\"~\")[0].strip()\n",
        "    inputs = ols.split(\"~\")[1].strip().split(\" + \")\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(df[inputs], df[target])\n",
        "\n",
        "    return model.coef_[inputs.index(\"a\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### synthetic data generation for CPD project"
      ],
      "metadata": {
        "id": "gUVU7daXT-WU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BYjxlHoc2ee_"
      },
      "outputs": [],
      "source": [
        "def observed(n=100, ols=\"y ~ a + c1 + c2\"):\n",
        "    np.random.seed(88)\n",
        "    # confounders = race (c1) and gender (c2)\n",
        "    c1 = np.random.binomial(n=1, p=0.423, size=n)\n",
        "\n",
        "    # choose p based on distribution of male vs female officers in the data\n",
        "    c2 = np.random.binomial(n=1, p=0.8763, size=n)\n",
        "\n",
        "    # low rank vs high rank\n",
        "    # p = 0.3 + 0.2c1 + 0.2c2 (default prob of promotion is 0.3 but goes up w/ race/gender 1)\n",
        "    a = np.random.binomial(n=1, p=0.3 + 0.2*c1 + 0.2 * c2, size=n)\n",
        "\n",
        "    # hard to do w/ 7 bc want to fit with different models to see how well you're fitting counterfactuals\n",
        "    # vector of weights to rep prob of suspension at each rank\n",
        "    weights = np.random.uniform(0, 0.5, 2)\n",
        "    weights.sort()\n",
        "    weights = weights[::-1]\n",
        "    print(\"weights: \", weights)\n",
        "    print(\"expected causal effect: \", weights[1]-weights[0])\n",
        "\n",
        "    y = []\n",
        "\n",
        "    # relationship b/t a and y should be small weight - big weight\n",
        "    for i in range(n):\n",
        "      rank = a[i]\n",
        "      p = (c1[i] + c2[i]) / 4 + weights[rank]\n",
        "      p = min(p, 1)\n",
        "      y.append(np.random.binomial(n=1, p=p))\n",
        "    y = np.array(y)\n",
        "\n",
        "    df = pd.DataFrame(data=dict(c1=c1, c2=c2, a=a, y=y))\n",
        "    a_param = get_smf_model_a_param(ols, df)\n",
        "    naive_a = get_smf_model_a_param(\"y ~ a\", df)\n",
        "\n",
        "    print(\"naive estimate: \", naive_a)\n",
        "    # print(\"observed causal effect with backdoor: \", a_param)\n",
        "\n",
        "    return a_param"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"observed causal effect with backdoor: \", observed(n=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EVGQrF6blzq",
        "outputId": "b982b699-22a1-4565-948b-950d767dc295"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights:  [0.15010261 0.00617352]\n",
            "expected causal effect:  -0.14392909686181932\n",
            "naive estimate:  -0.1010109308697455\n",
            "observed causal effect with backdoor:  -0.17863670285842156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"observed causal effect with backdoor: \", observed(n=10000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U14qlIhjUUUP",
        "outputId": "4243cc16-96fa-4a99-9091-1f69d7ace164"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights:  [0.28190298 0.11372635]\n",
            "expected causal effect:  -0.16817663430800922\n",
            "naive estimate:  -0.09584415584415641\n",
            "observed causal effect with backdoor:  -0.1660791639489527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"observed causal effect with backdoor: \", observed(n=100000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIQ6ZEzFUXiL",
        "outputId": "104a1c3e-af5b-4e98-ae61-6ac6e5fbf3bf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights:  [0.45014063 0.29954051]\n",
            "expected causal effect:  -0.1506001262063042\n",
            "naive estimate:  -0.07708963852378756\n",
            "observed causal effect with backdoor:  -0.14968755812279524\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}